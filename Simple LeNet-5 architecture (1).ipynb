{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import all useful libraries\n#Data Processing libraries\nimport numpy as np\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator               # used for data augmentation\n#ML Libraries\nimport tensorflow as tf\nimport keras \nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense, Conv2D, AveragePooling2D, Flatten, Dropout","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read train and test data\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect the shape of the dataset\nprint(train.shape)\nprint(test.shape)\n# 784 = pixels of a 28x28 image\n# 785 = pixels of a 28x28 image + class of the data\n# The large dimention is the dimention with no of examples","execution_count":4,"outputs":[{"output_type":"stream","text":"(42000, 785)\n(28000, 784)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into x and y\ny_train = train['label']\nx_train = train.drop(labels = ['label'],axis = 1)\n\n#clear up the memory\ndel train\n\n# print the y_train which has the class of each data\ny_train","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"0        1\n1        0\n2        1\n3        4\n4        0\n        ..\n41995    0\n41996    1\n41997    7\n41998    6\n41999    9\nName: label, Length: 42000, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale values to between 0 and 1 for faster learning\nx_train = x_train/255\n\n# you want number of imput channels to be last index for this version of keras\nimage_size = int(np.sqrt(x_train.shape[1]))\n\nip_shape = (image_size, image_size, 1)\nx_train = x_train.values.reshape(x_train.shape[0], image_size, image_size, 1)\n\n# convert y to one hot vectors for training\ny_train = keras.utils.np_utils.to_categorical(y_train.values, num_classes=10)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array([[0., 1., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train.shape = ', x_train.shape)\nprint('y_train.shape = ', y_train.shape)\n\n# 42000 = number of examples\n# 28    = no of pixels\n# 1     = number of channels ( the image is black/white so has only one channel)\n# 10    = number of classes","execution_count":8,"outputs":[{"output_type":"stream","text":"x_train.shape =  (42000, 28, 28, 1)\ny_train.shape =  (42000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process the test model similarly\ntest = test/255\ntest = test.values.reshape(test.shape[0], image_size, image_size, 1)\n\nprint(test.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(28000, 28, 28, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep aside a part of the training set (10000 examples ) for development\nx_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=10000, random_state = 12)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect the shape to make sure the train dev split was successful\nprint('x_train.shape = ', x_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('x_dev.shape   = ', x_dev.shape)\nprint('y_dev.shape   = ', y_dev.shape)","execution_count":11,"outputs":[{"output_type":"stream","text":"x_train.shape =  (32000, 28, 28, 1)\ny_train.shape =  (32000, 10)\nx_dev.shape   =  (10000, 28, 28, 1)\ny_dev.shape   =  (10000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build a keras model\nmodel = keras.Sequential()\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=ip_shape ))\nmodel.add(AveragePooling2D())\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\nmodel.add(AveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(units=120, activation='relu'))\nmodel.add(Dense(units=84, activation='relu'))\nmodel.add(Dense(units=10, activation = 'softmax'))\n# even though the original paper did not use relu we'll use it as it is better.\n# The reason why relu wasn't used on the og paper was because it was not famous at the time of writing the paper","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary of the model descriing it's structure\nmodel.summary()","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 26, 26, 6)         60        \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 13, 13, 6)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 11, 11, 16)        880       \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 5, 5, 16)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 400)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 120)               48120     \n_________________________________________________________________\ndense_2 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                850       \n=================================================================\nTotal params: 60,074\nTrainable params: 60,074\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the model with a loss function and an optimizer\nmodel.compile(loss = keras.losses.categorical_crossentropy,\n             optimizer = keras.optimizers.Adam(),\n             metrics = ['accuracy'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model for 15 epochs using batches of size 128\nmodel.fit(x_train, y_train, batch_size = 128, epochs = 15)","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n32000/32000 [==============================] - 6s 172us/step - loss: 0.5687 - accuracy: 0.8434\nEpoch 2/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.1725 - accuracy: 0.9482\nEpoch 3/15\n32000/32000 [==============================] - 5s 158us/step - loss: 0.1092 - accuracy: 0.9678\nEpoch 4/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.0850 - accuracy: 0.9740\nEpoch 5/15\n32000/32000 [==============================] - 5s 165us/step - loss: 0.0706 - accuracy: 0.9788\nEpoch 6/15\n32000/32000 [==============================] - 5s 169us/step - loss: 0.0604 - accuracy: 0.9812\nEpoch 7/15\n32000/32000 [==============================] - 5s 167us/step - loss: 0.0505 - accuracy: 0.9847\nEpoch 8/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.0467 - accuracy: 0.9853\nEpoch 9/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.0407 - accuracy: 0.9872\nEpoch 10/15\n32000/32000 [==============================] - 5s 164us/step - loss: 0.0368 - accuracy: 0.9882\nEpoch 11/15\n32000/32000 [==============================] - 5s 166us/step - loss: 0.0312 - accuracy: 0.9906\nEpoch 12/15\n32000/32000 [==============================] - 5s 162us/step - loss: 0.0281 - accuracy: 0.9910\nEpoch 13/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.0242 - accuracy: 0.9924\nEpoch 14/15\n32000/32000 [==============================] - 5s 158us/step - loss: 0.0231 - accuracy: 0.9924\nEpoch 15/15\n32000/32000 [==============================] - 5s 159us/step - loss: 0.0210 - accuracy: 0.9935\n","name":"stdout"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f43d7fb6a10>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# crosscheck with dev set for overfitting\ndev_loss, dev_metric = model.evaluate(x_dev, y_dev)\nprint('Accuracy = ', dev_metric)","execution_count":16,"outputs":[{"output_type":"stream","text":"10000/10000 [==============================] - 1s 106us/step\nAccuracy =  0.9854000210762024\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Since the difference in performance between train and dev set is <1% overfitting is very minimal"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the results \nresults = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"array([2, 0, 9, ..., 3, 9, 2])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the resuts into a dataframs with the appropriate ImageId\nresults_df = pd.DataFrame()\nresults_df['ImageId'] = np.arange(len(results)) + 1\nresults_df['Label'] = pd.Series(results)\nresults_df","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"       ImageId  Label\n0            1      2\n1            2      0\n2            3      9\n3            4      9\n4            5      3\n...        ...    ...\n27995    27996      9\n27996    27997      7\n27997    27998      3\n27998    27999      9\n27999    28000      2\n\n[28000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>27996</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>27997</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>27998</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>27999</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>28000</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save the results as a dataframe for submission\nresults_df.to_csv('submission.csv', index = False)","execution_count":19,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}